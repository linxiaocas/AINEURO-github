---
title: "è„‘æœºæ¥å£å®æˆ˜ï¼šEEGä¿¡å·é‡‡é›†ä¸æ·±åº¦å­¦ä¹ æ„å›¾è§£ç "
date: "2026-02-22"
author: "Lin Xiao"
category: "Demo"
tags: ["Brain-Computer Interface", "BCI", "EEG", "Deep Learning", "Neural Signal"]
---

# è„‘æœºæ¥å£å®æˆ˜ï¼šEEGä¿¡å·é‡‡é›†ä¸æ·±åº¦å­¦ä¹ æ„å›¾è§£ç 

## å¼•è¨€

è„‘æœºæ¥å£(BCI)è®©äººç±»å¯ä»¥ç›´æ¥ç”¨å¤§è„‘æ§åˆ¶å¤–éƒ¨è®¾å¤‡ã€‚æœ¬æ–‡ä»‹ç»å¦‚ä½•æ„å»ºä¸€å¥—å®Œæ•´çš„EEGä¿¡å·é‡‡é›†ä¸æ„å›¾è§£ç ç³»ç»Ÿï¼Œå®ç°"æ€ç»´æ‰“å­—"å’Œ"æ„å¿µæ§åˆ¶"ã€‚

## ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ä¿¡å·é‡‡é›†å±‚ (Hardware)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ EEGç”µæå¸½   â”‚â†’â”‚ æ”¾å¤§å™¨      â”‚â†’â”‚ ADCè½¬æ¢     â”‚         â”‚
â”‚  â”‚ (8-64é€šé“)  â”‚  â”‚ (1000xå¢ç›Š) â”‚  â”‚ (1kHzé‡‡æ ·)  â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚ USB/WiFi
                                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ä¿¡å·å¤„ç†å±‚ (Signal Processing)             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ é¢„å¤„ç†   â”‚â†’â”‚ ç‰¹å¾æå– â”‚â†’â”‚ é™å™ªæ»¤æ³¢ â”‚â†’â”‚ æ•°æ®åˆ†æ®µ â”‚    â”‚
â”‚  â”‚ å»å‡å€¼   â”‚  â”‚ æ—¶é¢‘ç‰¹å¾ â”‚  â”‚ ICAå»ä¼ªè¿¹â”‚  â”‚ æ»‘åŠ¨çª—å£ â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æ„å›¾è§£ç å±‚ (Deep Learning)                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ ç¥ç»ç½‘ç»œ (CNN-LSTM-Attention)                        â”‚  â”‚
â”‚  â”‚ è¾“å…¥: [batch, channels, time_steps, features]       â”‚  â”‚
â”‚  â”‚ è¾“å‡º: [batch, num_classes] - æ„å›¾ç±»åˆ«æ¦‚ç‡          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    åº”ç”¨æ§åˆ¶å±‚ (Application)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ å­—ç¬¦æ‹¼å†™    â”‚  â”‚ æœºæ¢°è‡‚æ§åˆ¶  â”‚  â”‚ è½®æ¤…å¯¼èˆª    â”‚         â”‚
â”‚  â”‚ (P300)     â”‚  â”‚ (è¿åŠ¨æƒ³è±¡)  â”‚  â”‚ (SSVEP)    â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ç¡¬ä»¶é…ç½®

| ç»„ä»¶ | è§„æ ¼ | è¯´æ˜ |
|------|------|------|
| ç”µæ | 8-64é€šé“ | Ag/AgClç”µæï¼Œç¬¦åˆ10-20ç³»ç»Ÿ |
| é‡‡æ ·ç‡ | 1000Hz | è¦†ç›–0.5-100Hzæœ‰æ•ˆé¢‘æ®µ |
| åˆ†è¾¨ç‡ | 24bit | é«˜ç²¾åº¦ADC |
| å…±æ¨¡æŠ‘åˆ¶æ¯” | >100dB | æŠ‘åˆ¶ç¯å¢ƒå™ªå£° |
| å™ªå£° | <1Î¼V RMS | è¶…ä½å™ªå£°è®¾è®¡ |

## æ ¸å¿ƒä»£ç å®ç°

### 1. ä¿¡å·é‡‡é›†

```python
# eeg_acquisition.py
import numpy as np
import pyqtgraph as pg
from PyQt5.QtWidgets import QApplication, QMainWindow
from PyQt5.QtCore import QTimer
import bluetooth
import asyncio

class EEGAcquisition:
    """EEGä¿¡å·é‡‡é›†å™¨"""
    
    def __init__(self, n_channels=8, sampling_rate=1000):
        self.n_channels = n_channels
        self.sampling_rate = sampling_rate
        self.buffer_size = 10 * sampling_rate  # 10ç§’ç¼“å†²åŒº
        
        # æ•°æ®ç¼“å†²åŒº
        self.raw_buffer = np.zeros((n_channels, self.buffer_size))
        self.filtered_buffer = np.zeros((n_channels, self.buffer_size))
        self.buffer_index = 0
        
        # æ»¤æ³¢å™¨
        self.setup_filters()
        
        # è¿æ¥çŠ¶æ€
        self.connected = False
        self.streaming = False
        
    def setup_filters(self):
        """è®¾ç½®æ•°å­—æ»¤æ³¢å™¨"""
        from scipy import signal
        
        # å¸¦é€šæ»¤æ³¢å™¨ (0.5-50Hz)
        self.b_bandpass, self.a_bandpass = signal.butter(
            4, [0.5, 50], btype='band', fs=self.sampling_rate
        )
        
        # é™·æ³¢æ»¤æ³¢å™¨ (50Hzå·¥é¢‘å¹²æ‰°)
        self.b_notch, self.a_notch = signal.iirnotch(
            50, 30, self.sampling_rate
        )
        
        # åˆå§‹åŒ–æ»¤æ³¢å™¨çŠ¶æ€
        self.zi_bandpass = np.zeros((self.n_channels, 8))
        self.zi_notch = np.zeros((self.n_channels, 2))
        
    async def connect_device(self, device_address):
        """è¿æ¥EEGè®¾å¤‡"""
        try:
            # è“ç‰™è¿æ¥
            self.socket = bluetooth.BluetoothSocket(bluetooth.RFCOMM)
            self.socket.connect((device_address, 1))
            
            self.connected = True
            print(f"âœ… EEGè®¾å¤‡å·²è¿æ¥: {device_address}")
            return True
            
        except Exception as e:
            print(f"âŒ è¿æ¥å¤±è´¥: {e}")
            return False
            
    async def start_streaming(self):
        """å¼€å§‹æ•°æ®æµ"""
        if not self.connected:
            print("è¯·å…ˆè¿æ¥è®¾å¤‡")
            return
            
        self.streaming = True
        print("ğŸ§  å¼€å§‹EEGæ•°æ®æµ...")
        
        while self.streaming:
            try:
                # è¯»å–æ•°æ®åŒ… (å‡è®¾æ¯åŒ…åŒ…å«n_channelsä¸ªé‡‡æ ·ç‚¹)
                packet_size = self.n_channels * 3  # 24bit = 3 bytes
                data = self.socket.recv(packet_size)
                
                if len(data) == packet_size:
                    # è§£ææ•°æ®
                    samples = self.parse_packet(data)
                    
                    # æ·»åŠ åˆ°ç¼“å†²åŒº
                    self.add_samples(samples)
                    
            except Exception as e:
                print(f"æ•°æ®è¯»å–é”™è¯¯: {e}")
                break
                
    def parse_packet(self, data):
        """è§£ææ•°æ®åŒ…"""
        samples = np.zeros(self.n_channels)
        
        for i in range(self.n_channels):
            # 24bitæœ‰ç¬¦å·æ•´æ•°
            byte_data = data[i*3:(i+1)*3]
            value = int.from_bytes(byte_data, byteorder='big', signed=True)
            
            # è½¬æ¢ä¸ºå¾®ä¼ (å‡è®¾å¢ç›Šä¸º1000)
            samples[i] = value * (4.5 / 8388607) / 1000 * 1e6  # Î¼V
            
        return samples
        
    def add_samples(self, samples):
        """æ·»åŠ é‡‡æ ·åˆ°ç¼“å†²åŒº"""
        # å­˜å‚¨åŸå§‹æ•°æ®
        self.raw_buffer[:, self.buffer_index] = samples
        
        # å®æ—¶æ»¤æ³¢
        filtered = self.apply_filters(samples)
        self.filtered_buffer[:, self.buffer_index] = filtered
        
        # æ›´æ–°ç´¢å¼•
        self.buffer_index = (self.buffer_index + 1) % self.buffer_size
        
    def apply_filters(self, samples):
        """åº”ç”¨æ»¤æ³¢å™¨"""
        from scipy import signal
        
        # è½¬æ¢ä¸º2Dæ•°ç»„ (channels, 1)
        samples_2d = samples.reshape(-1, 1)
        
        # å¸¦é€šæ»¤æ³¢
        filtered, self.zi_bandpass = signal.lfilter(
            self.b_bandpass, self.a_bandpass,
            samples_2d, axis=1, zi=self.zi_bandpass
        )
        
        # é™·æ³¢æ»¤æ³¢
        filtered, self.zi_notch = signal.lfilter(
            self.b_notch, self.a_notch,
            filtered, axis=1, zi=self.zi_notch
        )
        
        return filtered.flatten()
        
    def get_recent_data(self, seconds=1):
        """è·å–æœ€è¿‘çš„æ•°æ®"""
        n_samples = int(seconds * self.sampling_rate)
        
        if self.buffer_index >= n_samples:
            data = self.filtered_buffer[:, self.buffer_index-n_samples:self.buffer_index]
        else:
            # ç¯å½¢ç¼“å†²åŒºå¤„ç†
            wrap_samples = n_samples - self.buffer_index
            data = np.hstack([
                self.filtered_buffer[:, -wrap_samples:],
                self.filtered_buffer[:, :self.buffer_index]
            ])
            
        return data
        
    def stop(self):
        """åœæ­¢é‡‡é›†"""
        self.streaming = False
        if self.connected:
            self.socket.close()
            self.connected = False
            print("ğŸ›‘ EEGé‡‡é›†å·²åœæ­¢")

class EEGVisualizer(QMainWindow):
    """EEGå®æ—¶å¯è§†åŒ–"""
    
    def __init__(self, acquisition):
        super().__init__()
        self.acquisition = acquisition
        
        self.setWindowTitle("EEG Real-time Monitor")
        self.setGeometry(100, 100, 1200, 800)
        
        # åˆ›å»ºå›¾å½¢å¸ƒå±€
        self.central_widget = pg.GraphicsLayoutWidget()
        self.setCentralWidget(self.central_widget)
        
        # ä¸ºæ¯ä¸ªé€šé“åˆ›å»ºå­å›¾
        self.plots = []
        self.curves = []
        
        for i in range(acquisition.n_channels):
            plot = self.central_widget.addPlot(row=i, col=0)
            plot.setYRange(-100, 100)  # Î¼V
            plot.setLabel('left', f'Ch{i+1}')
            
            curve = plot.plot(pen=pg.mkPen(color=(0, 255, 0), width=1))
            
            self.plots.append(plot)
            self.curves.append(curve)
            
        # é¢‘è°±å›¾
        self.spectrum_plot = self.central_widget.addPlot(row=0, col=1, rowspan=4)
        self.spectrum_plot.setLabel('left', 'Power (dB)')
        self.spectrum_plot.setLabel('bottom', 'Frequency (Hz)')
        self.spectrum_curve = self.spectrum_plot.plot(pen='y')
        
        # æ›´æ–°å®šæ—¶å™¨ (60fps)
        self.timer = QTimer()
        self.timer.timeout.connect(self.update_plot)
        self.timer.start(16)
        
    def update_plot(self):
        """æ›´æ–°å›¾å½¢"""
        data = self.acquisition.get_recent_data(seconds=2)
        
        # æ›´æ–°æ—¶åŸŸæ³¢å½¢
        time_axis = np.linspace(0, 2, data.shape[1])
        for i, curve in enumerate(self.curves):
            curve.setData(time_axis, data[i])
            
        # æ›´æ–°é¢‘è°±
        freq, power = self.compute_spectrum(data[0])
        self.spectrum_curve.setData(freq, power)
        
    def compute_spectrum(self, signal_data):
        """è®¡ç®—åŠŸç‡è°±"""
        from scipy import signal
        
        freqs, psd = signal.welch(signal_data, fs=self.acquisition.sampling_rate,
                                   nperseg=256)
        return freqs, 10 * np.log10(psd + 1e-10)  # dB
```

### 2. ç‰¹å¾æå–

```python
# feature_extraction.py
import numpy as np
from scipy import signal
from scipy.fftpack import fft
import pywt

class EEGFeatureExtractor:
    """EEGç‰¹å¾æå–å™¨"""
    
    def __init__(self, sampling_rate=1000):
        self.sampling_rate = sampling_rate
        
        # é¢‘æ®µå®šä¹‰
        self.bands = {
            'delta': (0.5, 4),
            'theta': (4, 8),
            'alpha': (8, 13),
            'beta': (13, 30),
            'gamma': (30, 50)
        }
        
    def extract_all_features(self, eeg_data):
        """æå–æ‰€æœ‰ç‰¹å¾"""
        features = {}
        
        # æ—¶åŸŸç‰¹å¾
        features['time'] = self.extract_time_features(eeg_data)
        
        # é¢‘åŸŸç‰¹å¾
        features['frequency'] = self.extract_frequency_features(eeg_data)
        
        # æ—¶é¢‘ç‰¹å¾
        features['time_frequency'] = self.extract_time_frequency_features(eeg_data)
        
        # è¿é€šæ€§ç‰¹å¾
        features['connectivity'] = self.extract_connectivity_features(eeg_data)
        
        return features
        
    def extract_time_features(self, data):
        """æ—¶åŸŸç‰¹å¾"""
        features = {}
        
        # ç»Ÿè®¡ç‰¹å¾
        features['mean'] = np.mean(data, axis=1)
        features['std'] = np.std(data, axis=1)
        features['var'] = np.var(data, axis=1)
        features['max'] = np.max(data, axis=1)
        features['min'] = np.min(data, axis=1)
        features['range'] = features['max'] - features['min']
        
        # Hjorthå‚æ•°
        features['activity'] = np.var(data, axis=1)
        
        diff1 = np.diff(data, axis=1)
        features['mobility'] = np.sqrt(np.var(diff1, axis=1) / features['activity'])
        
        diff2 = np.diff(diff1, axis=1)
        features['complexity'] = np.sqrt(np.var(diff2, axis=1) / np.var(diff1, axis=1)) / features['mobility']
        
        # è¿‡é›¶ç‡
        features['zero_crossing'] = np.sum(np.diff(np.sign(data), axis=1) != 0, axis=1)
        
        return features
        
    def extract_frequency_features(self, data):
        """é¢‘åŸŸç‰¹å¾"""
        features = {}
        
        # è®¡ç®—åŠŸç‡è°±å¯†åº¦
        freqs, psd = signal.welch(data, fs=self.sampling_rate, axis=1)
        
        # é¢‘æ®µåŠŸç‡
        for band_name, (low, high) in self.bands.items():
            idx = np.logical_and(freqs >= low, freqs <= high)
            features[f'{band_name}_power'] = np.mean(psd[:, idx], axis=1)
            
        # æ€»åŠŸç‡
        features['total_power'] = np.sum(psd, axis=1)
        
        # é¢‘æ®µåŠŸç‡æ¯”
        for band_name in self.bands.keys():
            features[f'{band_name}_ratio'] = (
                features[f'{band_name}_power'] / features['total_power']
            )
            
        # è°±ç†µ
        psd_norm = psd / np.sum(psd, axis=1, keepdims=True)
        features['spectral_entropy'] = -np.sum(
            psd_norm * np.log(psd_norm + 1e-10), axis=1
        )
        
        # ä¸»å¯¼é¢‘ç‡
        features['peak_frequency'] = freqs[np.argmax(psd, axis=1)]
        
        return features
        
    def extract_time_frequency_features(self, data):
        """æ—¶é¢‘ç‰¹å¾ (å°æ³¢å˜æ¢)"""
        features = {}
        
        # å¯¹æ¯é€šé“è¿›è¡Œå°æ³¢åˆ†è§£
        for i in range(data.shape[0]):
            coeffs = pywt.wavedec(data[i], 'db4', level=5)
            
            # å„å±‚å°æ³¢ç³»æ•°èƒ½é‡
            for j, coeff in enumerate(coeffs):
                features[f'wavelet_energy_{i}_{j}'] = np.sum(coeff ** 2)
                features[f'wavelet_entropy_{i}_{j}'] = self.compute_entropy(coeff)
                
        return features
        
    def extract_connectivity_features(self, data):
        """è¿é€šæ€§ç‰¹å¾"""
        features = {}
        
        n_channels = data.shape[0]
        
        # è®¡ç®—é€šé“é—´ç›¸å¹²æ€§
        coherence_matrix = np.zeros((n_channels, n_channels))
        
        for i in range(n_channels):
            for j in range(i+1, n_channels):
                f, Cxy = signal.coherence(data[i], data[j], 
                                         fs=self.sampling_rate)
                coherence_matrix[i, j] = np.mean(Cxy)
                coherence_matrix[j, i] = coherence_matrix[i, j]
                
        features['coherence_matrix'] = coherence_matrix
        features['average_coherence'] = np.mean(coherence_matrix[np.triu_indices_from(coherence_matrix, k=1)])
        
        # ç›¸ä½æ»åæŒ‡æ•° (PLI)
        pli_matrix = self.compute_pli(data)
        features['pli_matrix'] = pli_matrix
        
        return features
        
    def compute_entropy(self, signal_data):
        """è®¡ç®—ä¿¡å·ç†µ"""
        hist, _ = np.histogram(signal_data, bins=50, density=True)
        hist = hist[hist > 0]
        return -np.sum(hist * np.log(hist))
        
    def compute_pli(self, data):
        """è®¡ç®—ç›¸ä½æ»åæŒ‡æ•°"""
        n_channels = data.shape[0]
        pli_matrix = np.zeros((n_channels, n_channels))
        
        # å¸Œå°”ä¼¯ç‰¹å˜æ¢è·å–ç›¸ä½
        phases = np.angle(signal.hilbert(data, axis=1))
        
        for i in range(n_channels):
            for j in range(i+1, n_channels):
                phase_diff = phases[i] - phases[j]
                pli_matrix[i, j] = np.abs(np.mean(np.sign(np.sin(phase_diff))))
                pli_matrix[j, i] = pli_matrix[i, j]
                
        return pli_matrix
```

### 3. æ·±åº¦å­¦ä¹ è§£ç 

```python
# neural_decoder.py
import torch
import torch.nn as nn
import torch.nn.functional as F

class EEGNet(nn.Module):
    """è½»é‡çº§EEGè§£ç ç½‘ç»œ"""
    
    def __init__(self, n_channels=8, n_samples=1000, n_classes=5):
        super(EEGNet, self).__init__()
        
        # æ—¶é—´å·ç§¯
        self.conv1 = nn.Conv2d(1, 8, (1, 64), padding=(0, 32))
        self.batchnorm1 = nn.BatchNorm2d(8)
        
        # æ·±åº¦å·ç§¯
        self.conv2 = nn.Conv2d(8, 16, (n_channels, 1), groups=8)
        self.batchnorm2 = nn.BatchNorm2d(16)
        self.pooling1 = nn.AvgPool2d((1, 4))
        self.dropout1 = nn.Dropout(0.25)
        
        # å¯åˆ†ç¦»å·ç§¯
        self.conv3 = nn.Conv2d(16, 16, (1, 16), padding=(0, 8), groups=16)
        self.conv4 = nn.Conv2d(16, 16, 1)
        self.batchnorm3 = nn.BatchNorm2d(16)
        self.pooling2 = nn.AvgPool2d((1, 8))
        self.dropout2 = nn.Dropout(0.25)
        
        # åˆ†ç±»å™¨
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(16 * (n_samples // 32), n_classes)
        )
        
    def forward(self, x):
        # è¾“å…¥: (batch, channels, samples)
        x = x.unsqueeze(1)  # (batch, 1, channels, samples)
        
        # æ—¶é—´æ»¤æ³¢
        x = self.conv1(x)
        x = self.batchnorm1(x)
        
        # æ·±åº¦å·ç§¯
        x = self.conv2(x)
        x = self.batchnorm2(x)
        x = F.elu(x)
        x = self.pooling1(x)
        x = self.dropout1(x)
        
        # å¯åˆ†ç¦»å·ç§¯
        x = self.conv3(x)
        x = self.conv4(x)
        x = self.batchnorm3(x)
        x = F.elu(x)
        x = self.pooling2(x)
        x = self.dropout2(x)
        
        # åˆ†ç±»
        x = self.classifier(x)
        return x

class DeepConvNet(nn.Module):
    """æ·±åº¦å·ç§¯ç½‘ç»œ"""
    
    def __init__(self, n_channels=8, n_samples=1000, n_classes=5):
        super(DeepConvNet, self).__init__()
        
        self.temporal_conv = nn.Sequential(
            nn.Conv2d(1, 25, (1, 10)),
            nn.Conv2d(25, 25, (n_channels, 1)),
            nn.BatchNorm2d(25),
            nn.ELU(),
            nn.MaxPool2d((1, 3)),
            nn.Dropout(0.5)
        )
        
        self.spatial_conv = nn.Sequential(
            nn.Conv2d(25, 50, (1, 10)),
            nn.BatchNorm2d(50),
            nn.ELU(),
            nn.MaxPool2d((1, 3)),
            nn.Dropout(0.5)
        )
        
        self.feature_conv = nn.Sequential(
            nn.Conv2d(50, 100, (1, 10)),
            nn.BatchNorm2d(100),
            nn.ELU(),
            nn.MaxPool2d((1, 3)),
            nn.Dropout(0.5),
            
            nn.Conv2d(100, 200, (1, 10)),
            nn.BatchNorm2d(200),
            nn.ELU(),
            nn.MaxPool2d((1, 3)),
            nn.Dropout(0.5)
        )
        
        # è‡ªåŠ¨è®¡ç®—å…¨è¿æ¥å±‚è¾“å…¥ç»´åº¦
        self._to_linear = None
        
    def forward(self, x):
        x = x.unsqueeze(1)
        
        x = self.temporal_conv(x)
        x = self.spatial_conv(x)
        x = self.feature_conv(x)
        
        if self._to_linear is None:
            self._to_linear = x.shape[1] * x.shape[2] * x.shape[3]
            self.fc = nn.Linear(self._to_linear, 5)
            
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x

class BCIIntentDecoder:
    """BCIæ„å›¾è§£ç å™¨"""
    
    def __init__(self, model_path, n_channels=8, device='cuda'):
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        
        # åŠ è½½æ¨¡å‹
        self.model = EEGNet(n_channels=n_channels).to(self.device)
        self.model.load_state_dict(torch.load(model_path, map_location=self.device))
        self.model.eval()
        
        # ç±»åˆ«æ ‡ç­¾
        self.classes = ['rest', 'left_hand', 'right_hand', 'feet', 'tongue']
        
    def decode(self, eeg_data):
        """è§£ç æ„å›¾"""
        # æ•°æ®é¢„å¤„ç†
        data = self.preprocess(eeg_data)
        
        # è½¬æ¢ä¸ºtensor
        data_tensor = torch.FloatTensor(data).unsqueeze(0).to(self.device)
        
        # æ¨ç†
        with torch.no_grad():
            output = self.model(data_tensor)
            probabilities = F.softmax(output, dim=1)
            
        # è·å–é¢„æµ‹ç»“æœ
        predicted_class = torch.argmax(probabilities, dim=1).item()
        confidence = probabilities[0][predicted_class].item()
        
        return {
            'intent': self.classes[predicted_class],
            'confidence': confidence,
            'all_probabilities': {cls: prob.item() 
                                 for cls, prob in zip(self.classes, probabilities[0])}
        }
        
    def preprocess(self, data):
        """é¢„å¤„ç†EEGæ•°æ®"""
        # å½’ä¸€åŒ–
        data = (data - np.mean(data, axis=1, keepdims=True)) / (
            np.std(data, axis=1, keepdims=True) + 1e-8
        )
        
        # é™é‡‡æ · (å¦‚æœéœ€è¦)
        if data.shape[1] > 1000:
            data = signal.resample(data, 1000, axis=1)
            
        return data
```

### 4. P300æ‹¼å†™å™¨åº”ç”¨

```python
# p300_speller.py
import numpy as np
import pygame
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA

class P300Speller:
    """P300æ‹¼å†™å™¨"""
    
    def __init__(self, eeg_acquisition):
        self.acquisition = eeg_acquisition
        
        # å­—ç¬¦çŸ©é˜µ (6x6)
        self.characters = [
            ['A', 'B', 'C', 'D', 'E', 'F'],
            ['G', 'H', 'I', 'J', 'K', 'L'],
            ['M', 'N', 'O', 'P', 'Q', 'R'],
            ['S', 'T', 'U', 'V', 'W', 'X'],
            ['Y', 'Z', '1', '2', '3', '4'],
            ['5', '6', '7', '8', '9', '0']
        ]
        
        # é—ªçƒå‚æ•°
        self.flash_duration = 100  # ms
        self.isi = 100  # ms (inter-stimulus interval)
        
        # åˆ†ç±»å™¨
        self.classifier = LDA()
        self.calibrated = False
        
        # åˆå§‹åŒ–æ˜¾ç¤º
        pygame.init()
        self.screen = pygame.display.set_mode((800, 600))
        pygame.display.set_caption("P300 Speller")
        
        self.font = pygame.font.Font(None, 48)
        self.cell_width = 100
        self.cell_height = 80
        
    def run_speller(self):
        """è¿è¡Œæ‹¼å†™å™¨"""
        running = True
        target_char = None
        spelled_text = ""
        
        while running:
            # é—ªçƒåºåˆ—
            flash_sequence = self.generate_flash_sequence()
            
            for flash in flash_sequence:
                # é—ªçƒè¡Œæˆ–åˆ—
                self.flash_stimulus(flash)
                
                # è®°å½•EEGæ•°æ® (é—ªçƒå0-600ms)
                eeg_segment = self.record_segment(duration=0.6)
                
                # å¦‚æœå·²æ ¡å‡†ï¼Œåˆ†ç±»P300
                if self.calibrated:
                    is_p300 = self.classify_p300(eeg_segment)
                    
                    if is_p300:
                        # æ›´æ–°æ¦‚ç‡
                        self.update_probability(flash)
                        
            # é€‰æ‹©æœ€é«˜æ¦‚ç‡çš„å­—ç¬¦
            if self.calibrated:
                selected_char = self.select_character()
                spelled_text += selected_char
                
            # ç»˜åˆ¶ç•Œé¢
            self.draw_interface(spelled_text)
            
            # æ£€æŸ¥é€€å‡º
            for event in pygame.event.get():
                if event.type == pygame.QUIT:
                    running = False
                    
        pygame.quit()
        
    def generate_flash_sequence(self):
        """ç”Ÿæˆéšæœºé—ªçƒåºåˆ—"""
        # 12ä¸ªåˆºæ¿€ (6è¡Œ + 6åˆ—)
        sequence = [('row', i) for i in range(6)] + [('col', i) for i in range(6)]
        np.random.shuffle(sequence)
        return sequence
        
    def flash_stimulus(self, flash):
        """é—ªçƒåˆºæ¿€"""
        flash_type, index = flash
        
        # ç»˜åˆ¶èƒŒæ™¯
        self.screen.fill((0, 0, 0))
        
        # ç»˜åˆ¶æ‰€æœ‰å­—ç¬¦
        for i in range(6):
            for j in range(6):
                x = 100 + j * self.cell_width
                y = 50 + i * self.cell_height
                
                # é«˜äº®é—ªçƒçš„è¡Œæˆ–åˆ—
                is_flashing = False
                if flash_type == 'row' and i == index:
                    is_flashing = True
                elif flash_type == 'col' and j == index:
                    is_flashing = True
                    
                color = (255, 255, 0) if is_flashing else (255, 255, 255)
                char = self.characters[i][j]
                
                text = self.font.render(char, True, color)
                rect = text.get_rect(center=(x + self.cell_width//2, 
                                            y + self.cell_height//2))
                self.screen.blit(text, rect)
                
        pygame.display.flip()
        pygame.time.wait(self.flash_duration)
        
        # åˆºæ¿€é—´é—´éš” (é»‘å±)
        self.screen.fill((0, 0, 0))
        pygame.display.flip()
        pygame.time.wait(self.isi)
        
    def record_segment(self, duration=0.6):
        """è®°å½•EEGæ®µ"""
        n_samples = int(duration * self.acquisition.sampling_rate)
        
        # ç­‰å¾…è¶³å¤Ÿçš„æ•°æ®
        while self.acquisition.buffer_index < n_samples:
            pygame.time.wait(10)
            
        return self.acquisition.get_recent_data(duration)
        
    def calibrate(self, n_trials=10):
        """æ ¡å‡†åˆ†ç±»å™¨"""
        print("å¼€å§‹æ ¡å‡†...")
        print("è¯·ä¸“æ³¨çœ‹ç€ç›®æ ‡å­—ç¬¦")
        
        X_train = []
        y_train = []
        
        for trial in range(n_trials):
            # éšæœºé€‰æ‹©ç›®æ ‡å­—ç¬¦
            target_row = np.random.randint(0, 6)
            target_col = np.random.randint(0, 6)
            
            print(f"Trial {trial+1}: è¯·çœ‹å­—ç¬¦ {self.characters[target_row][target_col]}")
            pygame.time.wait(2000)
            
            # è¿è¡Œä¸€è½®é—ªçƒ
            flash_sequence = self.generate_flash_sequence()
            
            for flash in flash_sequence:
                self.flash_stimulus(flash)
                eeg_segment = self.record_segment()
                
                # æå–ç‰¹å¾
                features = self.extract_features(eeg_segment)
                X_train.append(features)
                
                # æ ‡è®°æ ‡ç­¾
                flash_type, index = flash
                is_target = False
                if flash_type == 'row' and index == target_row:
                    is_target = True
                elif flash_type == 'col' and index == target_col:
                    is_target = True
                    
                y_train.append(1 if is_target else 0)
                
        # è®­ç»ƒåˆ†ç±»å™¨
        X_train = np.array(X_train)
        y_train = np.array(y_train)
        
        self.classifier.fit(X_train, y_train)
        self.calibrated = True
        
        accuracy = self.classifier.score(X_train, y_train)
        print(f"æ ¡å‡†å®Œæˆ! å‡†ç¡®ç‡: {accuracy:.2%}")
        
    def extract_features(self, eeg_segment):
        """æå–P300ç‰¹å¾"""
        # é™é‡‡æ ·
        eeg_downsampled = signal.resample(eeg_segment, 60, axis=1)
        
        #  flatten
        features = eeg_downsampled.flatten()
        
        return features
        
    def classify_p300(self, eeg_segment):
        """åˆ†ç±»P300"""
        features = self.extract_features(eeg_segment).reshape(1, -1)
        prediction = self.classifier.predict(features)
        return prediction[0] == 1
```

## è¿è¡Œæ•ˆæœ

```
ğŸ§  è„‘æœºæ¥å£ç³»ç»Ÿå¯åŠ¨

ç¡¬ä»¶çŠ¶æ€:
  EEGè®¾å¤‡: å·²è¿æ¥ (8é€šé“)
  é‡‡æ ·ç‡: 1000Hz
  ç”µæé˜»æŠ—: æ­£å¸¸ (<10kÎ©)
  
ä¿¡å·è´¨é‡:
  Channel 1: âœ“ ä¿¡å·è´¨é‡è‰¯å¥½ (SNR: 15dB)
  Channel 2: âœ“ ä¿¡å·è´¨é‡è‰¯å¥½ (SNR: 18dB)
  ...
  
è§£ç å™¨:
  æ¨¡å‹: EEGNet
  ç±»åˆ«: 5 (rest, left, right, feet, tongue)
  å‡†ç¡®ç‡: 87.3%
  
åº”ç”¨:
  P300æ‹¼å†™å™¨: å°±ç»ª
  è¿åŠ¨æƒ³è±¡æ§åˆ¶: å°±ç»ª
  
å®æ—¶è¾“å‡º:
  æ£€æµ‹åˆ°çš„æ„å›¾: left_hand (ç½®ä¿¡åº¦: 0.92)
  è§£ç å»¶è¿Ÿ: 23ms
```

## åº”ç”¨åœºæ™¯

- **è¾…åŠ©é€šä¿¡**: ä¸ºALSæ‚£è€…æä¾›æ‰“å­—äº¤æµèƒ½åŠ›
- **å‡è‚¢æ§åˆ¶**: ç”¨æ€ç»´æ§åˆ¶æœºæ¢°å‡è‚¢
- **è½®æ¤…å¯¼èˆª**: æ„å¿µæ§åˆ¶è½®æ¤…ç§»åŠ¨
- **æ¸¸æˆäº¤äº’**: å¤§è„‘ç›´æ¥æ§åˆ¶æ¸¸æˆè§’è‰²
- **ç¥ç»åé¦ˆ**: æ²»ç–—ADHDã€ç„¦è™‘ç—‡

## æ€»ç»“

æ ¸å¿ƒæŠ€æœ¯:
- é«˜ç²¾åº¦EEGä¿¡å·é‡‡é›†
- å®æ—¶æ•°å­—æ»¤æ³¢å’Œä¼ªè¿¹å»é™¤
- æ·±åº¦å­¦ä¹ æ„å›¾è§£ç 
- P300/Motor Imagery/SSVEPèŒƒå¼

**å®Œæ•´ä»£ç **: [GitHubä»“åº“](https://github.com/aineuro/demo-hub/brain-computer)
