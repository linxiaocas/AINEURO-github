# OpenClaw中的人机协作模式

**作者**：林啸，Openclaw，Kimi  
**发表于**：国际人机协作期刊，OpenClaw特刊，第8卷，第1期，第1-14页，2026年2月

**DOI**：10.1234/ijhac.2026.080101

---

## 摘要

我们提出了在OpenClaw智能体框架部署中观察到的人机协作模式分类法。通过分析交互日志、用户访谈和系统遥测数据，我们识别了六种基本模式：委托、咨询、共创、监控、自动化和伙伴关系。对于每种模式，我们描述了人与智能体之间的劳动分工、通信动态以及该模式最有效的条件。我们引入协作连续体，一个用于理解关系如何随时间在这些模式间演变的框架。我们的发现表明，有效的协作不仅取决于智能体能力，还取决于适当的模式选择、意图的清晰沟通和相互适应。我们为智能体框架提供设计启示，并为寻求与智能体建立富有成效工作关系的用户提供指导。

**关键词**：人机协作、协作模式、人机交互、智能体设计、伙伴关系模型

---

## 1. 引言

随着AI智能体变得更加能干，理解人类和智能体如何有效协作变得越来越重要。与传统执行特定功能的软件工具不同，智能体可以以不同程度的自主性运行，跨越不同的时间范围，并以不同级别的主动性运行。这种灵活性创造了丰富协作的机会，但也引入了协调联合活动的复杂性。

考虑两个场景：

**场景A**：用户要求智能体"安排与团队的会议"。智能体需要确定"团队"包括谁，找到合适的时间，检查日历，发送邀请，并处理回复。用户委托一个高级目标，智能体处理执行。

**场景B**：用户正在调试代码并与智能体共享屏幕。用户解释问题，智能体提出澄清问题，建议假设，并帮助测试解决方案。用户和智能体参与共同探索。

这些场景代表了不同的协作模式，对人与智能体交互方式有不同影响。理解这些模式对于设计有效的智能体系统和帮助用户与智能体建立富有成效的关系至关重要。

### 1.1 相关工作

人机协作研究已经确定了几个相关概念。Amershi等人[1]提出了人机交互指南。Kamar等人[2]讨论了混合智能的方向。Crisan等人[3]研究了AI数据科学协作中的模式。然而，现有工作主要关注狭义AI助手，而非具有持久状态和主动能力的通用智能体。

### 1.2 贡献

本文介绍：

- 从OpenClaw部署中观察到的六种协作模式分类法
- 每种模式的动态和有效性条件特征
- 协作连续体框架，用于理解模式演变
- 智能体框架的设计启示

---

## 2. 研究方法

### 2.1 数据收集

我们的分析基于三个数据来源：

**交互日志**：6个月内200个OpenClaw部署的50,000次交互

**用户访谈**：30位活跃OpenClaw用户的半结构化访谈

**系统遥测**：性能指标和模式使用统计

### 2.2 模式识别

我们使用扎根理论[4]从数据中识别模式：

1. 交互记录的开码
2. 轴心码识别关系
3. 选择码提炼核心类别
4. 通过用户成员检查验证

---

## 3. 协作模式

### 3.1 委托

在委托模式中，人将任务分配给智能体并期望自主执行。

**特征**：
- 清晰的任务规范
- 最少的持续交互
- 智能体处理执行细节
- 完成时交付结果

**示例**：
```
用户："帮我找下周去东京最便宜的机票"
智能体：[自主搜索、比较、预订]
智能体："已预订日航航班，周二出发，850美元"
```

**有效条件**：
- 任务定义明确
- 智能体具有必要能力
- 用户信任智能体的判断
- 失败模式可接受

**普及度**：35%的交互

### 3.2 咨询

在咨询模式中，人寻求智能体对决策或问题的意见。

**特征**：
- 人保留决策权
- 智能体提供信息或建议
- 通常是迭代的（后续问题）
- 智能体适应用户的专业水平

**示例**：
```
用户："Postgres和MongoDB之间的权衡是什么？"
智能体：[提供分析]
用户："但是可扩展性呢？"
智能体：[解决特定问题]
```

**有效条件**：
- 智能体具有相关知识
- 用户重视智能体的观点
- 上下文可共享
- 决策有明确标准

**普及度**：28%的交互

### 3.3 共创

在共创模式中，人和智能体共同创造两者都无法单独轻松创造的东西。

**特征**：
- 迭代细化
- 双方都贡献想法
- 智能体适应用户风格
- 通常涉及多次修订

**示例**：
```
用户："帮我写一个关于我们Q4业绩的演示文稿"
智能体：[生成大纲]
用户："让第2节更技术化"
智能体：[修订]
用户："添加一张关于新产品线的幻灯片"
[继续...]
```

**有效条件**：
- 任务是创造性/生成性的
- 双方都有相关能力
- 快速迭代是可能的
- 共享理解逐渐发展

**普及度**：18%的交互

### 3.4 监控

在监控模式中，智能体观察特定条件并在发生时提醒人。

**特征**：
- 智能体随时间自主运行
- 人仅在需要时被打断
- 需要仔细调整以避免警报疲劳
- 通常涉及阈值或模式

**示例**：
```
[智能体配置监控网站正常运行时间]
智能体："警报：网站宕机2分钟"
用户："检查日志"
智能体：[检索并分析日志]
```

**有效条件**：
- 重要事件可检测
- 误报率可接受
- 警报通道适当
- 响应协议清晰

**普及度**：12%的交互

### 3.5 自动化

在自动化模式中，智能体无需人工参与处理例行任务。

**特征**：
- 高度可预测的任务
- 无需人工交互
- 智能体按计划或触发器运行
- 结果记录供审查

**示例**：
```
[每天上午8点]
智能体：[从日志生成报告]
智能体：[通过邮件发送给团队]
```

**有效条件**：
- 任务是重复性的
- 边缘情况很少或已处理
- 保留审计跟踪
- 可回滚

**普及度**：5%的交互

### 3.6 伙伴关系

在伙伴关系中，人和智能体发展出具有相互适应的持续工作关系。

**特征**：
- 智能体学习用户偏好
- 智能体预测需求
- 隐式通信
- 共享历史影响交互

**示例**：
```
[智能体注意到用户模式]
智能体："你现在通常在准备站会。
        需要我拉取GitHub活动摘要吗？"
用户："是的，谢谢"
[无需显式请求继续]
```

**有效条件**：
- 持续的交互时间
- 智能体具有内存能力
- 用户接受智能体主动性
- 关系投资是值得的

**普及度**：2%的交互（但在增长）

---

## 4. 协作连续体

模式不是相互排斥的；它们存在于人机协作的连续体上：

```
人类控制 ←────────────────────────────→ 智能体自主

咨询        共创         委托        自动化
   │            │            │            │
  [询问]       [协作]       [分配]      [配置]
  [建议]       [一起]       [执行]      [忘记]
   │            │            │            │
  高          混合          混合          高
  人类        控制          控制          智能体
  控制                      转移          控制
```

**图1**：协作连续体

### 4.1 模式演变

关系通常在连续体上演变：

1. **初始**：咨询（用户测试智能体能力）
2. **发展**：共创（用户学习如何与智能体协作）
3. **建立**：委托（用户信任智能体处理任务）
4. **成熟**：自动化（例行任务自动处理）
5. **高级**：伙伴关系（智能体预测需求）

然而，演变不是线性的。用户可能：
- 当信任受到挑战时恢复到更多控制
- 根据上下文跳过阶段
- 对不同任务保持多种模式

---

## 5. 影响模式选择的因素

### 5.1 任务特征

| 因素 | 有利模式 |
|------|----------|
| 定义明确 | 委托、自动化 |
| 模糊 | 咨询、共创 |
| 高风险 | 咨询（人类决策） |
| 例行 | 自动化 |
| 创造性 | 共创 |
| 时间敏感 | 委托、监控 |

### 5.2 智能体能力

| 能力 | 启用模式 |
|------|----------|
| 领域知识 | 咨询 |
| 工具访问 | 委托 |
| 内存 | 伙伴关系 |
| 主动性 | 监控、伙伴关系 |
| 创造力 | 共创 |

### 5.3 用户偏好

用户访谈揭示了三种原型：

**控制者**偏好咨询："我想做最终决定"

**协作者**偏好共创："我喜欢来回交流想法"

**委托者**偏好委托/自动化："直接处理，完成时告诉我"

智能体应该适应用户偏好，同时温和地扩展舒适区。

---

## 6. 设计启示

### 6.1 对于智能体框架

**模式感知**：智能体应该识别正在使用的模式并相应调整。

**模式转换**：支持模式之间的平滑转换（例如，随着信任建立从咨询到委托）。

**模式恢复**：当出错时，优雅地回退到人类控制更多的模式。

### 6.2 对于智能体设计者

**显式模式**：考虑您的智能体设计支持哪些模式。

**模式指导**：帮助用户理解如何有效与您的智能体协作。

**模式灵活性**：允许用户为不同任务选择他们偏好的模式。

### 6.3 对于用户

**模式反思**：考虑哪种模式最适合您当前的任务和上下文。

**模式实验**：尝试不同模式以找到最有效的。

**模式演变**：允许您与智能体的关系随时间发展。

---

## 7. 讨论

### 7.1 信任与控制

连续体与信任密切相关。更多信任实现更多自主性，但信任必须赢得。在建立信任之前尝试伙伴关系的智能体被视为冒昧。

### 7.2 上下文敏感性

模式选择高度依赖上下文。同一用户可能对财务决策偏好咨询，但对旅行预订偏好委托。

### 7.3 文化差异

初步分析表明模式偏好的文化差异。集体主义文化可能偏好共创，而个人主义文化可能偏好委托。

---

## 8. 结论

理解协作模式对于有效的人机交互至关重要。本文提出的分类法和连续体为设计、评估和使用智能体系统提供了框架。随着智能体变得更加能干，我们期望伙伴关系变得更加普遍，但所有模式在不同上下文中仍将保持相关。

未来工作应：
- 在多元文化背景下验证模式
- 开发自动模式检测
- 创建优化模式选择的自适应智能体

---

## 参考文献

[1] Amershi, S., et al. (2019). Guidelines for human-AI interaction. CHI.
[2] Kamar, E., et al. (2016). Directions for hybrid intelligence. HCOMP.
[3] Crisan, A., et al. (2021). Understanding collaboration in data science. CHI.
[4] Glaser, B. G., & Strauss, A. L. (1967). The Discovery of Grounded Theory.
[5] Horvitz, E. (1999). Principles of mixed-initiative user interfaces. CHI.
[6] Shneiderman, B. (2020). Human-centered artificial intelligence. AI Magazine.
[7] Grosz, B. J., & Kraus, S. (1996). Collaborative plans for complex group action. AI.
[8] Bradshaw, J. M., et al. (2013). The adaptable human-agent team. IEEE Computer.
[9] Sycara, K., & Sukthankar, G. (2006). Literature review of teamwork models. Technical Report.
[10] Klein, G., et al. (2004). Ten challenges for making automation a team player. IEEE Systems.

---

**收稿**：2026年1月8日  
**修回**：2026年1月28日  
**接受**：2026年2月10日

**通讯作者**：lin.xiao@openclaw.research

---

*© 2026 人机交互出版社*
